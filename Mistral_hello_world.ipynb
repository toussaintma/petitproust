{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2HLhsGHfUfYeS6sWrw/C2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toussaintma/petitproust/blob/main/Mistral_hello_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mistralai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOkqlZwN-igm",
        "outputId": "310e2c62-5c52-44ce-9385-79c3f4c99685"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-0.1.8-py3-none-any.whl (15 kB)\n",
            "Collecting httpx<0.26.0,>=0.25.2 (from mistralai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.10 (from mistralai)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from mistralai) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<0.26.0,>=0.25.2->mistralai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.26.0,>=0.25.2->mistralai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (4.11.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.26.0,>=0.25.2->mistralai) (1.2.1)\n",
            "Installing collected packages: orjson, h11, httpcore, httpx, mistralai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.25.2 mistralai-0.1.8 orjson-3.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f7MzW9_89Uhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8106f1a7-7597-49a6-f926-4043a1556ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "open-mistral-7b\n",
            "mistral-tiny-2312\n",
            "mistral-tiny\n",
            "open-mixtral-8x7b\n",
            "open-mixtral-8x22b\n",
            "open-mixtral-8x22b-2404\n",
            "mistral-small-2312\n",
            "mistral-small\n",
            "mistral-small-2402\n",
            "mistral-small-latest\n",
            "mistral-medium-latest\n",
            "mistral-medium-2312\n",
            "mistral-medium\n",
            "mistral-large-latest\n",
            "mistral-large-2402\n",
            "mistral-embed\n"
          ]
        }
      ],
      "source": [
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get(\"MI_TOKEN\")\n",
        "\n",
        "client = MistralClient(api_key=api_key)\n",
        "\n",
        "for m in client.list_models().data:\n",
        "    print(m.id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"mistral-large-latest\"\n",
        "temperature = 0.9\n",
        "\n",
        "messages = [\n",
        "    ChatMessage(role=\"system\", content=\"In the following chat conversation please answer to the user in French exclusively. Do not answer this message.\"),\n",
        "    ChatMessage(role=\"system\", content=\"Complete the phrase of the user in the litterary style of acclaimed french author Marcel Proust. Do not answer this message.\"),\n",
        "    ChatMessage(role=\"user\", content=\"Longtemps, je me suis levé de bonne\")\n",
        "]"
      ],
      "metadata": {
        "id": "V4KV-keBAWhY"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No streaming\n",
        "chat_response = client.chat(\n",
        "    model=model,\n",
        "    temperature=temperature,\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "print(chat_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsXSSoPu_Hzy",
        "outputId": "acab1d9b-7f7c-4267-83ff-0e66163359f8"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heure, car mon âme, intoxiquée par les parfums, les couleurs, les sons de la vie nocturne, avait besoin, pour se rafraîchir, des matinées paisibles et solennelles, où les premiers rayons du soleil, jouant à cache-cache avec les rideaux, venaient réveiller en moi les souvenirs enfouis et les rêves inachevés.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "f = open(\"/content/test-cases-fewshot-v1.json\", mode=\"r\", encoding=\"utf-8\")\n",
        "\n",
        "test_cases = json.load(f)\n",
        "output_cases = []\n",
        "for i in test_cases:\n",
        "    messages[2] = i[\"input\"]\n",
        "    output_cases.append({\n",
        "        \"input\": i[\"input\"],\n",
        "        \"in_training\": i[\"in_training\"],\n",
        "        \"creation\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"),\n",
        "        \"model\": model,\n",
        "        \"params\": f\"temperature:{temperature}\",\n",
        "        \"output\": chat_response.choices[0].message.content,\n",
        "        \"comment\": \"\",\n",
        "\n",
        "    })\n",
        "    print(output_cases[-1])\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZTydA97iRol",
        "outputId": "575668d9-8298-4f0b-b3a0-23df76e5de6d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Longtemps je me suis', 'creation': '2024-05-19T16:53:27.312048Z', 'model': 'mistral-large-latest', 'params': 'temperature:0.9', 'in_training': True, 'output': 'heure, car mon âme, intoxiquée par les parfums, les couleurs, les sons de la vie nocturne, avait besoin, pour se rafraîchir, des matinées paisibles et solennelles, où les premiers rayons du soleil, jouant à cache-cache avec les rideaux, venaient réveiller en moi les souvenirs enfouis et les rêves inachevés.', 'comment': ''}\n",
            "{'input': \"Les longues soirées d'automne\", 'creation': '2024-05-19T16:53:27.313168Z', 'model': 'mistral-large-latest', 'params': 'temperature:0.9', 'in_training': False, 'output': 'heure, car mon âme, intoxiquée par les parfums, les couleurs, les sons de la vie nocturne, avait besoin, pour se rafraîchir, des matinées paisibles et solennelles, où les premiers rayons du soleil, jouant à cache-cache avec les rideaux, venaient réveiller en moi les souvenirs enfouis et les rêves inachevés.', 'comment': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fout_name = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\") + \"_test_cases.json\"\n",
        "with open(fout_name, mode=\"w\", encoding=\"utf-8\") as fout:\n",
        "    json.dump(output_cases, fout, ensure_ascii=False, indent = 2)\n",
        "fout.close()"
      ],
      "metadata": {
        "id": "iUv8Uzb3mJKa"
      },
      "execution_count": 90,
      "outputs": []
    }
  ]
}